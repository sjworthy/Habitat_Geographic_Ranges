---
title: "GBIF"
output: html_document
date: "2024-11-22"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Install packages

```{r}
#install.packages("rgbif")
library(rgbif)
library(tidyverse)
```

Read in the species list

```{r}
species = read.csv("../Raw.Data/species.csv")
```

Getting taxon key/usage key for each species

```{r}
taxon.key=name_backbone_checklist(species$Scientific.Name)
head(taxon.key)
```

Issues found: 

* Taxodium ascendens and Taxodium distichum are synonyms, may be issue if have distinct microenvironments
* Fraxinus texensis is a synonym for Fraxinus albicans, Fraxinus albicans is not in the data set
* Quercus prinus and Quercus michauxii are synonyms, may be issue if have distinct microenvironments

```{r}
# match the names 
gbif_taxon_keys <- species$Scientific.Name %>% 
name_backbone_checklist() %>% # match to backbone 
filter(!matchType == "NONE") %>% # get matched names
pull(usageKey) 
```

Download the data

```{r}
occ_download(pred_in("taxonKey", gbif_taxon_keys),
             pred("hasGeospatialIssue", FALSE), # removes coordinates that are (0,0)
             pred("hasCoordinate", TRUE), # keeps only records with coordinates
             pred("occurrenceStatus","PRESENT"), # removes absent record
             pred("country", "US"), # country 
             pred_or(pred_lt("coordinateUncertaintyInMeters",10000),
                     pred_isnull("coordinateUncertaintyInMeters")), # coordinate Uncertainty is less than 10000 m or left blank
                  format = "SIMPLE_CSV") # return tsv file of occurrences
```

Citation Info:  
  Please always cite the download DOI when using this data.
  https://www.gbif.org/citation-guidelines
  DOI: 10.15468/dl.c24fgd
  Citation:
  GBIF Occurrence Download https://doi.org/10.15468/dl.c24fgd Accessed from R via rgbif (https://github.com/ropensci/rgbif) on 2024-12-01

Check status

```{r}
occ_download_wait('0010272-241126133413365')
```

Download data

```{r}
d = occ_download_get('0010272-241126133413365', path = "/Users/samanthaworthy/Documents/GitHub/Habitat_Geographic_Ranges/Raw.Data") %>%
  occ_download_import()
```

```{r}
head(d)
```

141 species, suppose to be 143. 

* Taxodium ascendens and Taxodium distichum are grouped as one species Taxondium distichum
* Fraxinus albicans instead of Fraxinus texensis
* Quercus michauxii and Quercus prinus are grouped as one species Quercus michauxii

```{r}
sort(unique(d$species))
```

```{r}
table(d$taxonRank)
```

Get rid of all taxonRanks excepts SPECIES and Quercus sinuata var. sinuata

```{r}
d.2 = d %>%
  filter(scientificName == "Quercus sinuata var. sinuata" | taxonRank == "SPECIES")
```

```{r}
sort(unique(d.2$species))
```

```{r}
table(d.2$taxonRank)
```


Following this for cleaning the data: https://ptarroso.github.io/ENMTutorial/chapter-1---the-presence-data-housekeeping.html. Some of this may be repetitive with settings for GBIF download but want to make sure the data is cleaned.

```{r}
install.packages("CoordinateCleaner")
library(CoordinateCleaner)
```

Remove rows with missing coordinates. All rows have coordinates

```{r}

table(is.na(d.2$decimalLatitude + d.2$decimalLongitude))
```

Remove vows that fail cleaning tests.

* "centroids" if the coordinate is exactly at the centroid of a country than it also indicates lack of precision
* "equal" if longitude and latitude are equal is often an error
* "gbif" tests if the coordinate refers to the GBIF headquarters
* "institutions" some coordinates might be attributes to the institution providing rather than to the observation location
* "zeros" if the coordinates are set to zero (intersection of equation with prime meridian)

```{r}
tests <- c("centroids", "equal", "gbif", "institutions", "zeros")

flags_d.2 <- clean_coordinates(x = d.2, lon = "decimalLongitude", lat = "decimalLatitude",
                                species = "species", countries = "countryCode",
                                country_refcol = "iso_a2", tests = tests)
```

Looking into which data points failed

```{r}
failed = flags_d.2 %>%
  filter(.summary == "FALSE")
```

Only keep the records that passed all the tests

```{r}
d.3 = d.2[flags_d.2$.summary,]
```

Already removed coordinates with uncertainty >=10000m

```{r}
range(d.3$coordinateUncertaintyInMeters, na.rm = TRUE)
```

Remove Fossil records

```{r}
table(d.3$basisOfRecord)
```
```{r}
d.4 = d.3 %>%
  filter(basisOfRecord != "FOSSIL_SPECIMEN")
```

Removing duplicated coordinates

```{r}
d.5 = d.4 %>%
  group_by(species) %>%
  distinct(decimalLatitude,decimalLongitude)
```

Check Map

```{r}
plot(d.5$decimalLongitude, d.5$decimalLatitude, asp=1, cex=0.3)
```

Remove records with longitude < -105 to keep eastern North America coordinates. Chose -105 since -104 is the western edge of Nebraska

```{r}
d.6 = d.5 %>%
  filter(decimalLongitude > -105)
```

```{r}
plot(d.6$decimalLongitude, d.6$decimalLatitude, asp=1, cex=0.3)
```

Trying to see which samples are those in the ocean

```{r}
d.7 = d.6 %>%
  cc_sea()
```

```{r}
plot(d.7$decimalLongitude, d.7$decimalLatitude, asp=1, cex=0.3)
```



